import { metadata } from "@/app/machine_learning/metadata";
import CustomLink from "@/app/components/CustomLink";

export default function PageContent() {
  const pagename: string = "randomforest"; //ここを変更

  const metaData = metadata[pagename];
  const basePath = process.env.NEXT_PUBLIC_BASE_PATH || "";
  const imagePath = `${basePath}/${metaData.topic}/${pagename}`;
  const notePath = `https://colab.research.google.com/github/jeonglabo/nextjs/blob/main/notebook/${metaData.topic}/${pagename}`;

  return (
    <>
      <h2 className="caption">ランダムフォレストの概要</h2>
      <p>
        ランダムフォレスト（Random
        Forest）は、機械学習におけるアンサンブル学習の一種で、複数の決定木（Decision
        Tree）を組み合わせることで予測精度を向上させるモデルです。
        <br />
        特に分類や回帰タスクにおいて高い汎化性能を発揮し、実務でも幅広く利用されています。
        <br />
        決定木については以下のページで詳しく解説しています。
      </p>
      <CustomLink
        href="/machine_learning/decisiontree"
        imageUrl={`${basePath}/machine_learning/decisiontree/thumb.png`}
        altText="決定木のページのサムネ"
        siteName={metadata.decisiontree.title}
        description={metadata.decisiontree.description}
      />
      <p>ランダムフォレストは、以下の特徴を持っています。</p>
      <ul>
        <li>汎化性能が高く、過学習しにくい。</li>
        <li>特徴量の重要度を解析可能。</li>
        <li>複雑なモデルの割に実装が簡単。</li>
      </ul>
      <h2 className="caption">ランダムフォレストの仕組み</h2>
      <p>
        ランダムフォレストは、複数の決定木を組み合わせることで、予測精度を向上させます。
        <br />
        以下にランダムフォレストの基本的な仕組みを示します。
      </p>
      <ul>
        <li>
          <b>データのランダムサンプリング</b>
          <p>
            元のデータセットから、ブートストラップサンプリングと呼ばれる手法で部分データセットを作成します。
            <br />
            このサンプリングにより、各決定木は異なる学習データを基に構築されます。
          </p>
        </li>
        <li>
          <b>決定木の構築</b>
          <p>
            各決定木では、データ分割時に全ての特徴量を使用するのではなく、ランダムに選ばれた一部の特徴量のみを利用します。
            <br />
            過学習を防ぐために、深さや葉の数に制限を設けることが一般的です。
          </p>
        </li>
        <li>
          <b>予測のアンサンブル</b>
          <p>
            分類問題では、全ての決定木の予測結果を多数決で統合します。
            <br />
            回帰問題では、全ての決定木の予測結果を平均して統合します。
            <br />
            これにより、個々の決定木の弱点を補い、安定した予測性能を実現します。
          </p>
        </li>
      </ul>
      <p>
        これにより、個々の決定木の弱点を補い、安定した予測性能を実現します。
      </p>
      <h2 className="caption">ランダムフォレストのアルゴリズム</h2>
      <p>ランダムフォレストのアルゴリズムは、以下の手順で構築されます。</p>
      <ol>
        <li>
          <b>データセットの準備</b>
          <p>
            ランダムなサブセットを作成し、決定木を構築するためのデータセットとします。
          </p>
        </li>
        <li>
          <b>ランダムフォレストの構築</b>
          <p>
            決定木を複数構築し、それぞれの決定木が異なる特徴量やデータで学習するようにします。
          </p>
        </li>
        <li>
          <b>予測の実行</b>
          <p>各決定木の予測結果を集計し、最終的な予測結果を出力します。</p>
        </li>
      </ol>
      <h2 className="caption">ランダムフォレストのメリット、デメリット</h2>
      <h3>メリット</h3>
      <ol>
        <li>
          <b>過学習しにくい</b>
          <p>アンサンブルによる分散を削減します。</p>
        </li>
        <li>
          <b>汎用性</b>
          <p>分類、回帰、多クラス問題に対応しています。</p>
        </li>
        <li>
          <b>特徴量の重要度解析</b>
          <p>特徴選択やデータ解釈に役立ちます。</p>
        </li>
        <li>
          <b>頑健性</b>
          <p>ノイズや欠損値に強いです。</p>
        </li>
      </ol>

      <h3>デメリット</h3>
      <ol>
        <li>
          <b>計算コストが高い</b>
          <p>大規模データセットでのトレーニングには時間がかかります。</p>
        </li>
        <li>
          <b>解釈が難しい</b>
          <p>個々の決定木がブラックボックス化することもあります。</p>
        </li>
        <li>
          <b>スケールに敏感</b>
          <p>特徴量のスケールを揃える必要がある場合があります。</p>
        </li>
      </ol>

      <h2 className="caption">ランダムフォレストの実装</h2>
      <p>
        ランダムフォレストは、Pythonの機械学習ライブラリであるScikit-learnを使用することで簡単に実装することができます。
        <br />
        今回の例では、Irisデータセットを使用し、分類問題を解きます。
      </p>
      <p>
        下記のnotebookは、ランダムフォレストを用いてIrisデータセットを分類するコードを示しています。
      </p>
      <CustomLink
        href={`${notePath}/randomforest.ipynb`}
        imageUrl={`${imagePath}/randomforest.png`}
        altText="ランダムフォレストの結果"
        siteName="ランダムフォレストの実装"
        description="ランダムフォレストの実装を行っているコードを示しています。"
        target="_blank"
      />
    </>
  );
}
